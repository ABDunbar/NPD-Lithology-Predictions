{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a dataframe\n",
    "from train_test_val import main\n",
    "# return train, train_labels, test, test_labels, val, val_labels\n",
    "from train_test_val import train_test_val_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from classification_utilities import display_cm, display_adj_cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = r\"C:\\Users\\Dunbar\\Dropbox\\Work\\FORCE\"\n",
    "infile = \"train.csv\"\n",
    "infile_path = os.path.join(path, infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values from curves:\n",
      "['RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC']\n",
      "----------------------------------------\n",
      "Group by: ['WELL', 'FORMATION']\n",
      "Total number of missing values: 1118313\n",
      "========================================\n",
      "Group by: ['WELL', 'GROUP']\n",
      "Total number of missing values: 981495\n",
      "========================================\n",
      "Group by: ['WELL']\n",
      "Total number of missing values: 415425\n",
      "========================================\n",
      "Group by: ['FORMATION']\n",
      "Total number of missing values: 6057\n",
      "========================================\n",
      "Group by: ['GROUP']\n",
      "Total number of missing values: 0\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "df = main(infile_path, 51, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AI\"] = df.DTC * df.RHOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalise(df, string):\n",
    "    _string = df[string].unique()\n",
    "    _dict = dict(zip(_string, range(len(_string))))\n",
    "    df = df.replace(_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = numericalise(df, \"FORMATION\")\n",
    "\n",
    "df = numericalise(df, \"GROUP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = ['DTC', 'FORMATION', 'GR', 'GROUP', 'NPHI',\n",
    "          'PEF', 'RDEP', 'RHOB', 'RMED', 'RSHA', 'AI', 'FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
    "# curves = ['RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC', 'AI']\n",
    "# curves = ['RSHA', 'RMED', 'RDEP', 'GR', 'NPHI', 'PEF', 'AI']\n",
    "# curves = ['RDEP', 'GR', 'NPHI', 'PEF', 'AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X = df[curves]\n",
    "X = shuffle(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = X.pop('FORCE_2020_LITHOFACIES_LITHOLOGY')\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.load('../penalty_matrix.npy')\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    S = 0.0\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    for i in range(0, y_true.shape[0]):\n",
    "        S -= A[y_true[i], y_pred[i]]\n",
    "    return S/y_true.shape[0]\n",
    "\n",
    "\n",
    "def make_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"Accuracy on test set: {:.3f}\".format(model.score(X_test, y_test)))\n",
    "    #print(\"Feature importances:\\n{}\".format(model.feature_importances_))\n",
    "    predictions = model.predict(X_test)\n",
    "    conf = confusion_matrix(y_test, predictions)\n",
    "    print(display_cm(conf, facies_labels, hide_zeros=True))\n",
    "    #print(confusion_matrix(y_test, predictions))\n",
    "    print(score(y_test.values, predictions))\n",
    "\n",
    "facies_labels = ['Sst', 'S-Sh', 'Sh', 'Mrl', 'Dol', 'Lst', 'Chk', 'Hal', 'Anh', 'Tuf', 'Coa', 'Bmt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons\n",
    "> Sensitive to noisy data. It can overfit noisy data.\n",
    "> The small variation(or variance) in data can result in the different decision tree. This can be reduced by bagging and boosting algorithms.\n",
    "> Decision trees are biased with imbalance dataset, so it is recommended that balance out the dataset before creating the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.999\n",
      "Accuracy on test set: 0.893\n",
      "Feature importances:\n",
      "[0.05883239 0.06576221 0.18114419 0.0777926  0.09668004 0.07038338\n",
      " 0.07142742 0.08718223 0.07709615 0.07846986 0.13522953]\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst  8559   620   761    10     2    80                       6    36       10074\n",
      "     S-Sh   594  7034   941    11     3   113                            15        8711\n",
      "       Sh   731   969 38277   174    30   539     3     7     4    65    44     2 40845\n",
      "      Mrl    19    16   161  1829     2   139     7                 2              2175\n",
      "      Dol     1     2    44     2    45     2                 2                      98\n",
      "      Lst    70   109   497   129     1  2782    43                24     1        3656\n",
      "      Chk     1                 1          38   702                                 742\n",
      "      Hal                 2           1               536     5                     544\n",
      "      Anh                 3     1     1                 5    53                      63\n",
      "      Tuf     5          50                16                     950              1021\n",
      "      Coa    33    21    46           1                                 168         269\n",
      "      Bmt                       2                                              11    13\n",
      "None\n",
      "-0.29766643210039434\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=0)\n",
    "make_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.999\n",
      "Accuracy on test set: 0.896\n",
      "Feature importances:\n",
      "[0.06224893 0.07944436 0.176415   0.08315882 0.10038391 0.06604921\n",
      " 0.06799717 0.08305034 0.06967084 0.07566848 0.13591293]\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst  8681   596   797     7          61                       5    39       10186\n",
      "     S-Sh   614  7159   895    18     4   103                       6    11        8810\n",
      "       Sh   730   934 38301   165    37   529           3     5    53    51       40808\n",
      "      Mrl    14     8   163  1892     1   108    10                                2196\n",
      "      Dol     2     4    29     1    37     1                 1     3                78\n",
      "      Lst    82    92   469   127        2825    45           2    16              3658\n",
      "      Chk     3           2     2          37   617                                 661\n",
      "      Hal                 4                           528     4                     536\n",
      "      Anh     1           4     1     2     2           6    59                      75\n",
      "      Tuf     5     1    57                20                     878               961\n",
      "      Coa    24    12    45     1           1                           154         237\n",
      "      Bmt           1                                                           4     5\n",
      "None\n",
      "-0.2901346557006934\n"
     ]
    }
   ],
   "source": [
    "# 33% of data, default parameters\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "make_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.998\n",
      "Accuracy on test set: 0.899\n",
      "Feature importances:\n",
      "[0.07278738 0.07392914 0.20300383 0.12102948 0.09294807 0.06552012\n",
      " 0.06387521 0.07262426 0.06419912 0.0746848  0.0953986 ]\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst  8733   606   737     8     1    69                       4    28       10186\n",
      "     S-Sh   591  7216   875     9     2   105                 2     1     9        8810\n",
      "       Sh   754   866 38362   151    33   515     2     2     5    65    53       40808\n",
      "      Mrl    10    11   174  1864     1   127     9                                2196\n",
      "      Dol     1     4    28     1    40     1                 1     2                78\n",
      "      Lst    76   107   463   123     1  2836    35           2    13     2        3658\n",
      "      Chk     2           1     9          25   624                                 661\n",
      "      Hal                 7                           527     2                     536\n",
      "      Anh     1           2                 2           5    65                      75\n",
      "      Tuf     3     2    61           1    18                     876               961\n",
      "      Coa    26    14    44                                             153         237\n",
      "      Bmt     1                                                                 4     5\n",
      "None\n",
      "-0.28374272478046064\n"
     ]
    }
   ],
   "source": [
    "#33% of available data, of which 20% test\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy', #\"gini\"\n",
    "    splitter='best',  #'best'\n",
    "    max_depth=30,#None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort=False,\n",
    ")\n",
    "make_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.998\n",
      "Accuracy on test set: 0.937\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst  9189   370   446     3          46                       1    11       10066\n",
      "     S-Sh   347  7856   551     7     3    55                 1           7        8827\n",
      "       Sh   431   587 39257   103    25   278           3     1    33    29       40747\n",
      "      Mrl     4     9    92  2012          86     3                                2206\n",
      "      Dol     1     3    24          61                       3                      92\n",
      "      Lst    58    54   363   102     2  3101    16                 6              3702\n",
      "      Chk                 2     2          19   717                                 740\n",
      "      Hal     1           5                           550                           556\n",
      "      Anh                 4           2                 4    58                      68\n",
      "      Tuf     1          30                12                     929               972\n",
      "      Coa    16     5    28                                             180         229\n",
      "      Bmt                 1                                                     6     7\n",
      "None\n",
      "-0.17579384858969097\n"
     ]
    }
   ],
   "source": [
    "#66% of available data, of which 10% test\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy', #\"gini\"\n",
    "    splitter='best',  #'best'\n",
    "    max_depth=30,#None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort=False,\n",
    ")\n",
    "make_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.996\n",
      "Accuracy on test set: 0.952\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst 14418   419   474     9     1    57                            18       15396\n",
      "     S-Sh   417 12193   699     8     1    65                       1     7       13391\n",
      "       Sh   484   680 60068    91    27   315     1     1     1    37    39       61744\n",
      "      Mrl     7    12   109  3070     1    92     2                                3293\n",
      "      Dol           3    29     5    89                             2               128\n",
      "      Lst    49    74   401    98     2  4954    35           1     8              5622\n",
      "      Chk                 2     6          23  1015                                1046\n",
      "      Hal                 1                           830     1                     832\n",
      "      Anh           1     3                             3   111                     118\n",
      "      Tuf     3     2    32                10                    1353              1400\n",
      "      Coa    31    11    34                                             295         371\n",
      "      Bmt                                                                      11    11\n",
      "None\n",
      "-0.13293405062311325\n"
     ]
    }
   ],
   "source": [
    "#100% of available data, of which 10% test\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy', #\"gini\"\n",
    "    splitter='best',  #'best'\n",
    "    max_depth=30,#None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort=False,\n",
    ")\n",
    "make_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_numbers = {30000: 0,\n",
    "                 65030: 1,\n",
    "                 65000: 2,\n",
    "                 80000: 3,\n",
    "                 74000: 4,\n",
    "                 70000: 5,\n",
    "                 70032: 6,\n",
    "                 88000: 7,\n",
    "                 86000: 8,\n",
    "                 99000: 9,\n",
    "                 90000: 10,\n",
    "                 93000: 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WELL', 'DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'GROUP', 'FORMATION',\n",
      "       'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n",
      "       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n",
      "       'ROPA', 'RXO'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "open_test_features = pd.read_csv('../test.csv', sep=';')\n",
    "\n",
    "# open_test_features.head()\n",
    "\n",
    "print(open_test_features.columns)\n",
    "\n",
    "open_test_features[\"AI\"] = open_test_features.DTC * open_test_features.RHOB\n",
    "open_test_features = numericalise(open_test_features, \"FORMATION\")\n",
    "open_test_features = numericalise(open_test_features, \"GROUP\")\n",
    "curves_test = ['DTC', 'FORMATION', 'GR', 'GROUP', 'NPHI',\n",
    "               'PEF', 'RDEP', 'RHOB', 'RMED', 'RSHA', 'AI']\n",
    "open_test_features = open_test_features[curves_test]\n",
    "open_test_features\n",
    "\n",
    "open_test_features = scaler.transform(open_test_features)\n",
    "open_test_features\n",
    "\n",
    "test_prediction = model.predict(open_test_features)\n",
    "\n",
    "# test_prediction\n",
    "\n",
    "\n",
    "\n",
    "category_to_lithology = {y:x for x,y in lithology_numbers.items()}\n",
    "\n",
    "test_prediction_for_submission = np.vectorize(category_to_lithology.get)(test_prediction)\n",
    "\n",
    "test_prediction_for_submission\n",
    "\n",
    "np.savetxt('test_predictions_rf_entropy.csv', test_prediction_for_submission, header='lithology', comments='', fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.998\n",
      "Accuracy on test set: 0.898\n",
      "Feature importances:\n",
      "[0.09079536 0.07873863 0.19720157 0.12533322 0.09160097 0.06734827\n",
      " 0.06279793 0.07292925 0.06223172 0.06938503 0.08163806]\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst  8613   604   733     9          68                       8    39       10074\n",
      "     S-Sh   606  7104   872    18     4    89                       1    17        8711\n",
      "       Sh   779   913 38370   147    25   482     3     5     2    68    49     2 40845\n",
      "      Mrl    10    16   159  1852     1   131     5                 1              2175\n",
      "      Dol           4    41     2    46     3                 2                      98\n",
      "      Lst    67   101   483   123     1  2822    35                23     1        3656\n",
      "      Chk                       1          34   707                                 742\n",
      "      Hal                 5           1               535     3                     544\n",
      "      Anh                 1           3                 6    53                      63\n",
      "      Tuf     5          55     1          13                     947              1021\n",
      "      Coa    32    13    53                 2                           169         269\n",
      "      Bmt                                                                      13    13\n",
      "None\n",
      "-0.28624965181568957\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy', #\"gini\"\n",
    "    splitter='best',  #'best'\n",
    "    max_depth=30,#None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort=False,\n",
    ")\n",
    "make_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.873\n",
      "Accuracy on test set: 0.851\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst  8041   576  1427     8           5                      12     5       10074\n",
      "     S-Sh  1129  5554  2001     5          14                       7     1        8711\n",
      "       Sh  1177   639 38675   115     1   133     4     7     2    89     3       40845\n",
      "      Mrl    21    26   379  1507         228    12                 2              2175\n",
      "      Dol     3     7    72     2     6     1           4     2     1                98\n",
      "      Lst   158   189   947   142        2120    60           2    38              3656\n",
      "      Chk     1           4     1          78   658                                 742\n",
      "      Hal                 6                           536     2                     544\n",
      "      Anh                12                             8    43                      63\n",
      "      Tuf     6          95                                       920              1021\n",
      "      Coa   111    11   137                                              10         269\n",
      "      Bmt     4                                                                 9    13\n",
      "None\n",
      "-0.41346153846153844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=1000,\n",
    "    max_samples=20000, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "make_model(bag_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.88530118 0.88429328 0.88599754 0.88797669 0.88507917]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "scores = cross_val_score(DecisionTreeClassifier(criterion='entropy',\n",
    "                                                splitter='best',\n",
    "                                                max_depth=30),\n",
    "                         X_train, y_train, cv=kfold)\n",
    "print(f\"Cross-validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.93375017 0.93162443 0.93272395 0.93265065 0.93166058]\n"
     ]
    }
   ],
   "source": [
    "#33% of data\n",
    "kfold = KFold(n_splits=5)\n",
    "scores = cross_val_score(DecisionTreeClassifier(criterion='entropy',\n",
    "                                                splitter='best',\n",
    "                                                max_depth=30),\n",
    "                         X, y, cv=kfold)\n",
    "print(f\"Cross-validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.93338367 0.93144851 0.93264332 0.9323941  0.93151398]\n"
     ]
    }
   ],
   "source": [
    "#66% of data\n",
    "kfold = KFold(n_splits=5)\n",
    "scores = cross_val_score(DecisionTreeClassifier(criterion='entropy',\n",
    "                                                splitter='best',\n",
    "                                                max_depth=30),\n",
    "                         X, y, cv=kfold)\n",
    "print(f\"Cross-validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.94852059 0.94855445 0.9485784  0.9481188  0.94752374]\n"
     ]
    }
   ],
   "source": [
    "#100% of data\n",
    "kfold = KFold(n_splits=5)\n",
    "scores = cross_val_score(DecisionTreeClassifier(criterion='entropy',\n",
    "                                                splitter='best',\n",
    "                                                max_depth=30),\n",
    "                         X, y, cv=kfold)\n",
    "print(f\"Cross-validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=30,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.1, n_estimators=1000, random_state=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=30), n_estimators=1000,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.1)\n",
    "\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.998\n",
      "Accuracy on test set: 0.966\n",
      "     Pred   Sst  S-Sh    Sh   Mrl   Dol   Lst   Chk   Hal   Anh   Tuf   Coa   Bmt Total\n",
      "     True\n",
      "      Sst 14739   277   332     3          31                            14       15396\n",
      "     S-Sh   290 12500   537     8     1    50                       1     4       13391\n",
      "       Sh   304   429 60701    71    14   177     1                21    26       61744\n",
      "      Mrl     5     6    87  3132          62     1                                3293\n",
      "      Dol     1     4    30     4    88                             1               128\n",
      "      Lst    51    63   393    78     1  4999    26           1    10              5622\n",
      "      Chk                 2     5          13  1026                                1046\n",
      "      Hal                 2                           828     2                     832\n",
      "      Anh           1     3                             4   110                     118\n",
      "      Tuf     1          32                 6                    1361              1400\n",
      "      Coa    18     7    33                 1                           312         371\n",
      "      Bmt                                                                      11    11\n",
      "None\n",
      "-0.09581575586345692\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(ada_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(ada_clf.score(X_test, y_test)))\n",
    "\n",
    "predictions = ada_clf.predict(X_test)\n",
    "conf = confusion_matrix(y_test, predictions)\n",
    "print(display_cm(conf, facies_labels, hide_zeros=True))\n",
    "\n",
    "print(score(y_test.values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_test_features = pd.read_csv('../test.csv', sep=';')\n",
    "\n",
    "# open_test_features.head()\n",
    "\n",
    "# print(open_test_features.columns)\n",
    "\n",
    "open_test_features[\"AI\"] = open_test_features.DTC * open_test_features.RHOB\n",
    "open_test_features = numericalise(open_test_features, \"FORMATION\")\n",
    "open_test_features = numericalise(open_test_features, \"GROUP\")\n",
    "curves_test = ['DTC', 'FORMATION', 'GR', 'GROUP', 'NPHI',\n",
    "               'PEF', 'RDEP', 'RHOB', 'RMED', 'RSHA', 'AI']\n",
    "open_test_features = open_test_features[curves_test]\n",
    "# print(open_test_features)\n",
    "\n",
    "open_test_features = scaler.transform(open_test_features)\n",
    "# print(open_test_features)\n",
    "\n",
    "test_prediction = ada_clf.predict(open_test_features)\n",
    "\n",
    "# print(test_prediction)\n",
    "\n",
    "category_to_lithology = {y:x for x,y in lithology_numbers.items()}\n",
    "\n",
    "test_prediction_for_submission = np.vectorize(category_to_lithology.get)(test_prediction)\n",
    "\n",
    "test_prediction_for_submission\n",
    "\n",
    "np.savetxt('test_predictions_ada-rf.csv', test_prediction_for_submission, header='lithology', comments='', fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
